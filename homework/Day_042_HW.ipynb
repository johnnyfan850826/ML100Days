{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [範例重點]\n",
    "了解機器學習建模的步驟、資料型態以及評估結果等流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "\n",
    "# 如果是分類問題，請使用 DecisionTreeClassifier，若為回歸問題，請使用 DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型四步驟\n",
    "\n",
    "在 Scikit-learn 中，建立一個機器學習的模型其實非常簡單，流程大略是以下四個步驟\n",
    "\n",
    "1. 讀進資料，並檢查資料的 shape (有多少 samples (rows), 多少 features (columns)，label 的型態是什麼？)\n",
    "    - 讀取資料的方法：\n",
    "        - **使用 pandas 讀取 .csv 檔：**pd.read_csv\n",
    "        - **使用 numpy 讀取 .txt 檔：**np.loadtxt \n",
    "        - **使用 Scikit-learn 內建的資料集：**sklearn.datasets.load_xxx\n",
    "    - **檢查資料數量：**data.shape (data should be np.array or dataframe)\n",
    "2. 將資料切為訓練 (train) / 測試 (test)\n",
    "    - train_test_split(data)\n",
    "3. 建立模型，將資料 fit 進模型開始訓練\n",
    "    - clf = DecisionTreeClassifier()\n",
    "    - clf.fit(x_train, y_train)\n",
    "4. 將測試資料 (features) 放進訓練好的模型中，得到 prediction，與測試資料的 label (y_test) 做評估\n",
    "    - clf.predict(x_test)\n",
    "    - accuracy_score(y_test, y_pred)\n",
    "    - f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取鳶尾花資料集\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=4)\n",
    "\n",
    "# 建立模型\n",
    "clf = DecisionTreeClassifier(criterion='gini',max_depth= None ,\n",
    "                             min_samples_split=2)\n",
    "\n",
    "# 訓練模型\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:  [0.01796599 0.         0.52229134 0.45974266]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importance: \", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "1. 試著調整 DecisionTreeClassifier(...) 中的參數，並觀察是否會改變結果？\n",
    "2. 改用其他資料集 (boston, wine)，並與回歸模型的結果進行比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.25, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.4, 22. , 21.1, 22.5, 44.8, 23.4, 34.9, 23.2, 17.2, 15.4, 24.1,\n",
       "       16.5, 22.7, 23.7, 22.6, 13.4, 16.2, 12.8, 10.4, 14.8, 10.4, 15.4,\n",
       "       21.5, 18.5, 19. , 21.4, 13.4, 15.2, 23. , 21.7,  9.5, 22.9, 36.5,\n",
       "       20.3, 13.1,  9.5, 33.2, 46. , 24.6, 23.7, 46. , 24.8, 12.7, 29.4,\n",
       "       25.1, 20.9, 50. , 19.4, 23. , 22.2, 30.8, 23.8, 11.3, 27.1, 15.7,\n",
       "       19.3, 22. , 33.1, 14.5, 33.1, 16.1, 21.4, 37. , 19.3, 43.1, 29.4,\n",
       "       21. ,  8.4, 23.2, 23.2, 21.7, 16.2, 22. , 30.1, 21.7, 33.4, 14.5,\n",
       "       22. , 17.7, 22.2, 21.7, 15.2, 26.6, 23. , 24.7, 20.6, 32.2, 24.5,\n",
       "       22.5, 50. , 29. , 50. , 19.4, 44.8, 24.4, 19.4, 20. , 23.1, 15.6,\n",
       "       19. ,  8.4, 19.3, 34.9, 14.5, 23.7, 20.6, 34.9, 30.3, 50. , 22.3,\n",
       "       22.2, 19.6, 13.2, 37. , 33.4, 29.6, 50. , 13.8,  7. , 19.6, 21.2,\n",
       "       12.5, 23.3, 22.6, 16.2, 24. , 50. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5, 24.8, 17.4, 19.3, 37.6, 24.2, 35.4, 19.9, 27.5, 17. , 31.2,\n",
       "       24.4, 16.1, 27. , 21. , 14.9, 18.9,  6.3, 16.3, 13.9,  8.8, 19.4,\n",
       "       18.8, 19.8, 17.5, 19.3, 20. , 14.3, 16.1, 19.5, 11. , 21.9, 31. ,\n",
       "       22. , 15.1, 13.3, 28.7, 46.7, 22.2, 22.8, 42.3, 41.3, 16.7, 31.1,\n",
       "       26.7, 19.4, 50. , 16.6, 19.5, 24.4, 28.5, 22.3, 12.1, 28.6, 15.6,\n",
       "       19.2, 27.5, 32. , 20.2, 32.4, 18.4, 19.9, 29.8, 20.1, 43.5, 24.5,\n",
       "       50. ,  7.2, 19.1, 21.2, 22.6, 22.9, 25. , 23.3, 17.3, 33. , 17.8,\n",
       "       23.8, 10.9, 18.6, 19.3, 16.7, 28. , 18.2, 29.1, 11.9, 32.7, 18.3,\n",
       "       22.4, 45.4, 31.5, 48.5, 19.8, 41.7, 22.2, 20.3, 20.7, 50. , 11.8,\n",
       "       19.5,  8.7, 23.3, 36.4, 13.3, 24.8, 20.4, 44. , 29. , 39.8, 22.9,\n",
       "       23. , 15.3, 23.7, 30.5, 33.2, 26.4, 50. , 14.2,  8.1, 16. , 20. ,\n",
       "        8.5, 23.7, 26.4, 18.5, 20. , 50. ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = metrics.mean_absolute_error(y_test, y_pred) # 使用 MAE 評估\n",
    "mse = metrics.mean_squared_error(y_test, y_pred) # 使用 MSE 評估\n",
    "r2 = metrics.r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3.418110236220472\n",
      "MSE:  28.65881889763779\n",
      "R-square:  0.7143644760680452\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE: \", mae)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"R-square: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
